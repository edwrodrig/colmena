\subsection{Computación distribuida}
La computación distribuida \cite{distributedcomputing} es una rama de las ciencias de la computación que estudia los sistemas distribuidos. Un sistema distribuido es una colección de entidades independientes que cooperan entre sí para resolver un problema determinado. Un sistema de computación distribuido (figura \ref{fig:image04}) se puede caracterizar como un conjunto de procesadores autónomos comunicados por una red que poseen las siguientes características:
\begin{itemize}
\item \textbf{Sin reloj físico en común :} Es una condición importante porque introduce el elemento de \emph{distribución} en el sistema y le da importancia a la inherente asincronía entre los procesadores.
\item \textbf{Sin memoria compartida :} Es una característica clave que requiere del paso de mensajes para la comunicación. Esta característica implica la carencia de un reloj físico común.
\item \textbf{Separación física :} La separación entre procesadores es la característica más representativa de un sistema distribuido. Sin embargo, no es necesario que estén separados a una escala de \emph{WAN}\footnote{Red de área amplia (Wide Area Network)}. Si los procesadores se encuentran en una sala dentro de una \emph{LAN}\footnote{Red de área local (Local Area Network)} también se consideran como separados.
\item \textbf{Autonomía y heterogeneidad :} Los procesadores pueden estar \emph{débilmente acoplados}, esto significa que pueden tener diferentes velocidades y corriendo diferentes sistemas operativos. Usualmente no son parte de un sistema dedicado pero cooperan unos con otros para ofrecer servicios o resolver problemas juntos.
\end{itemize}
\begin{figure}
\begin{center}
\includegraphics[width=0.7\textwidth]{images/image04.eps}
\end{center}
\caption{Un sistema distribuido conecta procesadores mediante una red de computación}
\label{fig:image04}
\end{figure}
\subsection{Computación paralela}
La computación paralela\cite{parallelcomputing} es un paradigma de la computación en donde se permite ejecutar más de una tarea simultáneamente. Se piensa que para que exista paralelismo se debe contar con múltiples procesadores, cosa que no es completamente necesaria ya que se puede emular el paralelismo mediante la concurrencia. Un sistema distribuido implica computación paralela ya que involucra múltiples procesadores.
\subsection{Computación P2P}
La computación P2P (Peer 2 Peer)\cite{p2pcomputing} representa computación sobre una red de capa de aplicación donde toda la interacción es no jerárquica, es decir, no existe una entidad coordinadora como en el paradigma cliente servidor. Esto comprende una serie de desafíos como mantener la consistencia de la información, la obtención eficiente de datos, la escalabilidad y la reconfiguración dinámica de la red dado que los nodos entran y salen aleatoriamente. Esta definición hace referencia en específico a la simetría en el rol de los nodos componentes de la red.
\subsection{Clusters}
Un cluster es un sistema de computación distribuida donde un grupo de computadores, comunicados por una red de alta velocidad, trabajan conjuntamente y aparecen ante el usuario como una sola máquina\cite{cluster}. En la mayoría de los casos, las máquinas que componen el cluster están dedicadas a tal función y por eso su configuración de software y hardware son especiales. Grandes empresas u organizaciones tales como \emph{IBM}, \emph{NASA}, \emph{Silicon Graphics} poseen sus propios clusters que por lo general son grandes habitaciones con una gran cantidad de computadores dedicados a sus necesidades de cómputo. El actual proyecto es presentado como un cluster virtual ya que hace que múltiples computadores no dedicados se vean ante el usuario como una sola máquina virtual.
\subsection{Computación de malla}
La computación de malla (Grid Computing)\cite{gridcomputing1}\cite{gridcomputing3} se refiere a recursos heterogeneos de comunicación, computación y almacenamiento distribuidos que pueden pertenecer a diferentes personas o dominios administrativos pero que son compartidos por los usuarios. Algunas cualidades que debe cumplir una malla son que sus recursos están coordinados pero no están sujetos a un control centralizado; usan protocolos e interfaces estándares, abiertas y de propósito general; y ofrecen calidad de servicios no triviales\cite{gridcomputing2}. No existe un consenso generalizado de lo que es un sistema de malla, pero se puede decir que es un sistema distribuido, donde sus recursos son poseídos por diferentes propietarios y compartidos entre ellos. Proyectos como \emph{BOINC}\cite{boinc}, \emph{XtremWeb}\cite{xtremweb} y \emph{Alchemi}\cite{alchemi} son ejemplos de ello.
\subsection{Computación de nube}
La computación de nube (Cloud Computing)\cite{cloudcomputing} se refiere a aplicaciones ofrecidas como servicios en Internet como también al hardware y sistemas de los centros de datos que proveen tales servicios. Cuando se referencia al servicio, generalmente se usa el término \emph{SaaS}\footnote{Software como servicio(Software as a Service)}, pero cuando se referencia al hardware y a los centros, se usa el término \emph{nube}.\\
Una \emph{nube pública} es cuando una nube se hace accesible al público mediante pago. A este servicio se le conoce como \emph{computación utilitaria}. Algunos ejemplos en la actualidad de esto son \emph{Amazon Web Services}\cite{amazonwebservicespage}, \emph{Google AppEngine}\cite{googleappenginepage} y \emph{Microsoft Azure}\cite{microsoftazurepage}. Estos servicios permiten a los usuarios correr sus aplicaciones sin la necesidad de tener un centro de cómputo. Desde un punto de vista basado en el hardware, hay tres aspectos que son nuevos en la computación de nube:
\begin{itemize}
\item La ilusión de infinitos recursos de hardware disponible, eliminando los planes de aprovisionamiento de hardware.
\item La posibilidad de pagar por usar recursos computacionales cuando son requeridos, evitando gastar en recursos innecesarios que no se estén usando.
\end{itemize}
En resumen, computación de nube más que una tecnología es un nuevo de modo de ver el hardware para los usuarios, donde existen entidades especializadas en proveer el uso de hardware como un servicio.
\subsection{Taxonomía de Flynn}
Flynn \cite{taxonomiaflynn} identificó cuatro modos de procesamiento basado en procesadores que ejecutan un mismo o diferente flujo de instrucciones, y si los procesadores ejecutan un mismo o diferente flujo de datos. Las configuraciones de sistemas que determinan los diferentes modos son\cite{taxonomiaflynn2}:
\begin{itemize}
\item \textbf{SISD (Flujo de instrucciones simple, flujo de datos simple) :} Corresponde al modo convencional de procesamiento con un CPU y un banco de memoria.
\item \textbf{SIMD (Flujo de instrucciones simple, flujo de datos múltiple) :} Corresponde a muchos procesadores iguales procesando múltiples datos. Aplicaciones que involucran operaciones en largos arreglos y matrices, como las aplicaciones científicas, pueden explotar sistemas que proveen esta configuración dado que el problema puede ser particionado fácilmente en muchos conjuntos de datos. Este es el modo que explotan los sistemas distribuidos a nivel de tareas y es el que explota el sistema de este proyecto.
\item \textbf{MISD (Flujo de instrucciones múltiples, flujo de datos simple) :} Este modo corresponde a la ejecución de diferentes operaciones sobre los mismos datos. Generalmente se ve en sistemas especializados que tienen un modelo tipo \emph{pipeline}.
\item \textbf{MIMD (Flujo de instrucciones múltiples, flujo de datos múltiples) :} En este modo, muchos procesadores ejecutan diferente código en diferentes datos. Es el modo más general. Este modo es común en sistemas distribuidos y en la gran mayoría de los sistemas paralelos. Este modo también es explotado por el sistema del presente proyecto.
\end{itemize}
\subsection{MPI}
MPI\footnote{Message Passing Interface}\cite{mpi} es una especificación de paso de mensajes usada en programación paralela. Su utilidad es permitir comunicar dos procesos a través de una red. Esto significa que MPI está enfocado al paralelismo que ocurre dentro de una aplicación, el que es muy diferente al paralelismo de tareas al que apunta el sistema el presente proyecto. Los niveles de paralelismo dependen de la unidad de procesamiento que se quiera considerar como atómica ya esta puede ir desde una instrucción del procesador hasta la ejecución de un programa. La ventaja de tomar un programa como unidad atómica es el hecho que la mayoría de las aplicaciones se proveen como ejecutables compilados o como codigos de fuente compilables. Si se quisiera aprovechar un paralelismo a nivel de instrucciones, como lo hace MPI, se necesitaría reprogramar las aplicaciones con la interfaz MPI, lo que es un trabajo complejo y laborioso. Incluso en el caso excepcional de que se estuviera dispuesto a hacer tal trabajo, no todas las aplicaciones ofrecen sus algoritmos y/o codigo fuente, lo que impide el proceso de ingeniería inversa. Resumiendo, MPI es una metodología que apunta a objetivos diferentes, como son la creación de aplicaciones paralelas nativas y no para adaptar aplicaciones ya disponibles a un sistema paralelo.

